{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea0582df-8485-4a93-a36e-db8504c790df",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3057f64f-c874-4044-84c8-1dfeebcf37dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\ml-course\\Computer Vision Projects\\virtualenv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import uuid\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b781d48-b4da-4508-9e4f-c4b3f234c0ca",
   "metadata": {},
   "source": [
    "## Detecting Landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e618d65e-133c-4078-bfb8-94b3b5e7f464",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "573f625d-8ab3-4d69-b2f4-014cb291fc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_hands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5) as hands:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # BGR TO RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.flip(image, 1)\n",
    "        \n",
    "        # SET FLAG\n",
    "        image.flags.writeable=False\n",
    "\n",
    "        # DETECTIONS\n",
    "        results = hands.process(image)\n",
    "\n",
    "        # SET FLAG TO TRUE\n",
    "        image.flags.writeable = True\n",
    "        \n",
    "        # RGB TO BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # DETECTIONS\n",
    "        # print(results)\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for num, hand in enumerate(results.multi_hand_landmarks):\n",
    "                mp_drawing.draw_landmarks(image, hand, mp_hands.HAND_CONNECTIONS,\n",
    "                                         mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "                                         mp_drawing.DrawingSpec(color=(121, 44, 250), thickness=2, circle_radius=4))\n",
    "        \n",
    "        cv2.imshow('Hand Tracking', image)\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b826de27-b6ed-45c2-a0d9-d58fcd809050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mp_drawing.draw_landmarks??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36a1fec-08e3-466f-871d-f0db1dd52f4c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Saving Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50b6101f-4da8-4eb1-bd36-a3c51c4db84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.mkdir('Output Images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b26cdaa-6b0e-4338-8d68-19a86ca3efdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# with mp_hands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5) as hands:\n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read()\n",
    "\n",
    "#         # BGR TO RGB\n",
    "#         image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#         image = cv2.flip(image, 1)\n",
    "        \n",
    "#         # SET FLAG\n",
    "#         image.flags.writeable=False\n",
    "\n",
    "#         # DETECTIONS\n",
    "#         results = hands.process(image)\n",
    "\n",
    "#         # SET FLAG TO TRUE\n",
    "#         image.flags.writeable = True\n",
    "        \n",
    "#         # RGB TO BGR\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "#         # DETECTIONS\n",
    "#         # print(results)\n",
    "\n",
    "#         if results.multi_hand_landmarks:\n",
    "#             for num, hand in enumerate(results.multi_hand_landmarks):\n",
    "#                 mp_drawing.draw_landmarks(image, hand, mp_hands.HAND_CONNECTIONS,\n",
    "#                                          mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "#                                          mp_drawing.DrawingSpec(color=(121, 44, 250), thickness=2, circle_radius=4))\n",
    "\n",
    "#         # SAVE IMAGE\n",
    "#         cv2.imwrite(os.path.join('Output Images', '{}.jpg'.format(uuid.uuid1())), image)\n",
    "#         cv2.imshow('Hand Tracking', image)\n",
    "#         if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "#             break\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79659000-04b4-43dc-a819-072c8a4d7fae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
